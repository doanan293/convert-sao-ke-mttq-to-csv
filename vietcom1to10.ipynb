{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-18T03:16:10.881414Z",
     "start_time": "2024-09-18T03:16:10.541727Z"
    }
   },
   "source": [
    "# Download PDF file\n",
    "import os\n",
    "from operator import lshift\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Get PDF document\n",
    "# pdf_path = \"./Data/Data_pdf/vietcom11.pdf\"\n",
    "pdf_path = \"./Data/Data_pdf/vietcom1to10.pdf\"\n",
    "\n",
    "# Download PDF if it doesn't already exist\n",
    "if not os.path.exists(pdf_path):\n",
    "    print(\"File doesn't exist, downloading...\")\n",
    "else:\n",
    "    print(f\"File {pdf_path} exists.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./Data/Data_pdf/vietcom1to10.pdf exists.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T03:16:17.970427Z",
     "start_time": "2024-09-18T03:16:11.528896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Requires !pip install PyMuPDF, see: https://github.com/pymupdf/pymupdf\n",
    "import fitz # (pymupdf, found this is better than pypdf for our use case, note: licence is AGPL-3.0, keep that in mind if you want to use any code commercially)\n",
    "from tqdm.auto import tqdm # for progress bars, requires !pip install tqdm \n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip() # note: this might be different for each doc (best to experiment)\n",
    "\n",
    "    # Other potential text formatting functions can go here\n",
    "    return cleaned_text\n",
    "\n",
    "# Open PDF and get lines/pages\n",
    "# Note: this only focuses on text, rather than images/figures etc\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing the page number\n",
    "        (adjusted), character count, word count, sentence count, token count, and the extracted text\n",
    "        for each page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)  # open a document\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        # pages_and_texts.append({\"page_number\": page_number+1,  # adjust page numbers since our PDF starts on page 42\n",
    "        #                         \"page_char_count\": len(text),\n",
    "        #                         \"page_word_count\": len(text.split(\" \")),\n",
    "        #                         \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "        #                         \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "        #                         \"text\": text})\n",
    "        pages_and_texts.append({\"page_number\": page_number,  # adjust page numbers since our PDF starts on page 42\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n"
   ],
   "id": "62259163af7bc4b0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin_hieunn/andoan/pdf2csv/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "12028it [00:06, 1901.11it/s]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T03:16:18.025791Z",
     "start_time": "2024-09-18T03:16:17.977035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Strings to remove\n",
    "strings_to_remove = [\n",
    "    \"SAO KÊ TÀI KHOẢN Tên tài khoản/Account name: Số tài khoản/Account number: Từ/ From:   01/09/2024 Đến/ To:  10/09/2024 CIF:                                ACCOUNT STATEMENT Ngày thực hiện/ Date: 11/09/2024 Chi nhánh thực hiện/ Branch:                0002040837 0011001932418 MAT TRAN TO QUOC VN - BAN CUU TRO TW Loại tiền/Currency: VND SỞ GIAO DỊCH Địa chỉ/ Address: 46 TRANG THI, HANOI Ngày GD/ TNX Date Số CT/ Doc No Số tiền ghi nợ/ Debit Số tiền ghi có/ Credit Số dư/ Balance Nội dung chi tiết/ Transactions in detail \",\n",
    "    \"Ngày GD/ TNX Date Số CT/ Doc No Số tiền ghi nợ/ Debit Số tiền ghi có/ Credit Số dư/ Balance Nội dung chi tiết/ Transactions in detail\"\n",
    "]\n",
    "\n",
    "# Function to remove specified strings\n",
    "def clean_text(text, strings_to_remove):\n",
    "    for string in strings_to_remove:\n",
    "        text = text.replace(string, \"\")\n",
    "    return text.strip()\n",
    "\n",
    "# Cleaning the texts\n",
    "pages_and_texts = [{'page_number': p['page_number'], 'text': clean_text(p['text'], strings_to_remove)} for p in pages_and_texts]"
   ],
   "id": "4b88009a2ece29a8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T03:16:18.051180Z",
     "start_time": "2024-09-18T03:16:18.038421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re # Extracting text data from the pages\n",
    "text_data = [page['text'] for page in pages_and_texts]\n",
    "\n",
    "# Combining all texts into one string\n",
    "combined_text = ' '.join(text_data)"
   ],
   "id": "c8b7b23c6bb42111",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T03:16:18.677947Z",
     "start_time": "2024-09-18T03:16:18.095938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Regular expression to extract the data for a single row format\n",
    "pattern = r\"(\\d{2}/\\d{2}/\\d{4}) (\\d+\\.\\d+) +([\\d\\.]+) (.+?)(?=\\d{2}/\\d{2}/\\d{4}|$)\"\n",
    "matches = re.findall(pattern, combined_text)\n"
   ],
   "id": "5f5c529bc6828a27",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T03:16:18.788942Z",
     "start_time": "2024-09-18T03:16:18.683448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = []\n",
    "for match in matches:\n",
    "    data.append([match[0], match[1], match[2], match[3]])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=['Date', 'ID', 'Money', 'Description'])"
   ],
   "id": "cbc10c4bea478596",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T03:16:20.324378Z",
     "start_time": "2024-09-18T03:16:20.097234Z"
    }
   },
   "cell_type": "code",
   "source": "df.to_csv(\"./Data/Data_csv/vietcom1to10.csv\", index=False)",
   "id": "544144be98efaa9e",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
